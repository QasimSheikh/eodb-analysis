{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082b7951-bde6-4fa7-a2bd-d25d802373b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostic Information:\n",
      "Sample Original EODB values: [185.21708367541348, 170.32868592710147, 192.69222167317545, 298.3302093157721, 363.09006849715695]\n",
      "\n",
      "Sample Prediction:\n",
      "Current State EODB: 47\n",
      "Actual Future EODB: 48\n",
      "Top Predicted States EODB values: [46, 46, 46]\n",
      "\n",
      "Feature Importance Analysis by Region Type:\n",
      "\n",
      "Eodb:\n",
      "  Linear region accuracy: 32.23%\n",
      "  Transition region accuracy: 41.67%\n",
      "\n",
      "Duration:\n",
      "  Linear region accuracy: 10.26%\n",
      "  Transition region accuracy: 0.00%\n",
      "\n",
      "Slope:\n",
      "  Linear region accuracy: 6.96%\n",
      "  Transition region accuracy: 0.00%\n",
      "\n",
      "Curvature:\n",
      "  Linear region accuracy: 98.90%\n",
      "  Transition region accuracy: 0.00%\n",
      "\n",
      "Duration-Slope Pattern Analysis:\n",
      "\n",
      "Linear Region Patterns:\n",
      "Duration: 39, Slope: 32\n",
      "Success Rate: 25.00% (1/4 predictions)\n",
      "Duration: 39, Slope: 30\n",
      "Success Rate: 0.00% (0/3 predictions)\n",
      "Duration: 38, Slope: 31\n",
      "Success Rate: 0.00% (0/3 predictions)\n",
      "Duration: 41, Slope: 35\n",
      "Success Rate: 0.00% (0/7 predictions)\n",
      "Duration: 42, Slope: 35\n",
      "Success Rate: 0.00% (0/5 predictions)\n",
      "\n",
      "Transition Region Patterns:\n",
      "Duration: 38, Slope: 28\n",
      "Success Rate: 0.00% (0/1 predictions)\n",
      "Duration: 40, Slope: 0\n",
      "Success Rate: 0.00% (0/1 predictions)\n",
      "Duration: 30, Slope: 27\n",
      "Success Rate: 0.00% (0/1 predictions)\n",
      "Duration: 36, Slope: 17\n",
      "Success Rate: 0.00% (0/1 predictions)\n",
      "\n",
      "Predictions completed and saved!\n"
     ]
    }
   ],
   "source": [
    "# Import cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "\n",
    "# Configuration cell\n",
    "INPUT_CONFIG = {\n",
    "    'transition_matrix_path': Path('data/matrix/transition_matrix.pkl'),\n",
    "    'features_path': Path('data/features/binned_features.pkl'),\n",
    "    'output_path': Path('data/predictions'),\n",
    "    'output_filename': 'predictions.pkl',\n",
    "    'n_steps_ahead': 3,\n",
    "    'display_count': 5\n",
    "}\n",
    "\n",
    "# Class Definitions\n",
    "class TransitionMatrix:\n",
    "    def __init__(self):\n",
    "        self.state_map = {}\n",
    "        self.reverse_map = {}\n",
    "        self.next_state_id = 0\n",
    "        self.counts = None\n",
    "        self.probability_matrix = None\n",
    "    \n",
    "    def get_state_id(self, features: Tuple) -> int:\n",
    "        if features not in self.state_map:\n",
    "            self.state_map[features] = self.next_state_id\n",
    "            self.reverse_map[self.next_state_id] = features\n",
    "            self.next_state_id += 1\n",
    "        return self.state_map[features]\n",
    "\n",
    "class BayesianPredictor:\n",
    "    def __init__(self, transition_matrix):\n",
    "        self.tm = transition_matrix\n",
    "        \n",
    "    def predict_next_n_states(self, current_state: int, n_steps: int = 1) -> np.ndarray:\n",
    "        current_dist = np.zeros(len(self.tm.state_map))\n",
    "        current_dist[current_state] = 1.0\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            current_dist = current_dist @ self.tm.probability_matrix\n",
    "            \n",
    "        return current_dist\n",
    "    \n",
    "    def get_top_k_states(self, probabilities: np.ndarray, k: int = 3) -> List[Tuple[int, float]]:\n",
    "        top_indices = np.argsort(probabilities)[-k:][::-1]\n",
    "        return [(idx, probabilities[idx]) for idx in top_indices]\n",
    "\n",
    "def predict_linear_region(current_state, pattern_analysis, predictor):\n",
    "    current_features = predictor.tm.reverse_map[current_state]\n",
    "    current_pattern = (current_features[1], current_features[2])  # duration, slope\n",
    "    \n",
    "    predicted_probs = predictor.predict_next_n_states(current_state)\n",
    "    initial_predictions = predictor.get_top_k_states(predicted_probs)\n",
    "    \n",
    "    weighted_predictions = []\n",
    "    for state_id, prob in initial_predictions:\n",
    "        weight = 1.0\n",
    "        \n",
    "        if current_pattern in pattern_analysis['success_rate']:\n",
    "            pattern_stats = pattern_analysis['success_rate'][current_pattern]\n",
    "            success_rate = pattern_stats['success'] / pattern_stats['total']\n",
    "            weight = weight * (1 + success_rate)\n",
    "            \n",
    "        weighted_predictions.append((state_id, prob * weight))\n",
    "    \n",
    "    total_weight = sum(w for _, w in weighted_predictions)\n",
    "    return [(s, w/total_weight) for s, w in weighted_predictions]\n",
    "\n",
    "def predict_transition_region(current_state, pattern_analysis, predictor):\n",
    "    predicted_probs = predictor.predict_next_n_states(current_state)\n",
    "    predictions = predictor.get_top_k_states(predicted_probs)\n",
    "    \n",
    "    # Focus on transitions to linear regions\n",
    "    weighted_predictions = []\n",
    "    for state_id, prob in predictions:\n",
    "        next_features = predictor.tm.reverse_map[state_id]\n",
    "        # Favor transitions back to linear regions\n",
    "        weight = 1.5 if next_features[3] == 0 else 1.0\n",
    "        weighted_predictions.append((state_id, prob * weight))\n",
    "    \n",
    "    total_weight = sum(w for _, w in weighted_predictions)\n",
    "    return [(s, w/total_weight) for s, w in weighted_predictions]\n",
    "\n",
    "def predict_with_region_awareness(current_state, pattern_analysis, predictor):\n",
    "    current_features = predictor.tm.reverse_map[current_state]\n",
    "    is_transition = current_features[3] > 0  # Check curvature\n",
    "    \n",
    "    if is_transition:\n",
    "        return predict_transition_region(current_state, pattern_analysis, predictor)\n",
    "    else:\n",
    "        return predict_linear_region(current_state, pattern_analysis, predictor)\n",
    "\n",
    "def make_predictions(predictor: BayesianPredictor, binned_features: Dict, n_steps: int) -> Dict:\n",
    "    initial_predictions = make_initial_predictions(predictor, binned_features, n_steps)\n",
    "    pattern_analysis = analyze_duration_slope_patterns(initial_predictions, predictor)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for series_id, features in binned_features.items():\n",
    "        series_predictions = []\n",
    "        \n",
    "        for i in range(len(features) - n_steps):\n",
    "            current_state = predictor.tm.get_state_id((\n",
    "                features[i]['eodb_bin'],\n",
    "                features[i]['duration_bin'],\n",
    "                features[i]['slope_bin'],\n",
    "                features[i]['curvature_bin']\n",
    "            ))\n",
    "            \n",
    "            actual_future_state = predictor.tm.get_state_id((\n",
    "                features[i + n_steps]['eodb_bin'],\n",
    "                features[i + n_steps]['duration_bin'],\n",
    "                features[i + n_steps]['slope_bin'],\n",
    "                features[i + n_steps]['curvature_bin']\n",
    "            ))\n",
    "            \n",
    "            top_predictions = predict_with_region_awareness(\n",
    "                current_state, \n",
    "                pattern_analysis,\n",
    "                predictor\n",
    "            )\n",
    "            \n",
    "            series_predictions.append({\n",
    "                'current_state': current_state,\n",
    "                'actual_future_state': actual_future_state,\n",
    "                'top_predictions': top_predictions\n",
    "            })\n",
    "            \n",
    "        predictions[series_id] = series_predictions\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def analyze_duration_slope_patterns(predictions, predictor):\n",
    "    patterns = {\n",
    "        'transitions': [],\n",
    "        'success_rate': {},\n",
    "        'common_errors': [],\n",
    "        'linear_patterns': {},\n",
    "        'transition_patterns': {}\n",
    "    }\n",
    "    \n",
    "    for series_id, series_preds in predictions.items():\n",
    "        for pred in series_preds:\n",
    "            current = predictor.tm.reverse_map[pred['current_state']]\n",
    "            actual = predictor.tm.reverse_map[pred['actual_future_state']]\n",
    "            predicted = predictor.tm.reverse_map[pred['top_predictions'][0][0]]\n",
    "            \n",
    "            is_transition = current[3] > 0\n",
    "            pattern_dict = patterns['transition_patterns'] if is_transition else patterns['linear_patterns']\n",
    "            \n",
    "            transition = {\n",
    "                'from_duration': current[1],\n",
    "                'from_slope': current[2],\n",
    "                'to_duration': actual[1],\n",
    "                'to_slope': actual[2],\n",
    "                'predicted_duration': predicted[1],\n",
    "                'predicted_slope': predicted[2],\n",
    "                'success': (actual[1] == predicted[1] and actual[2] == predicted[2])\n",
    "            }\n",
    "            patterns['transitions'].append(transition)\n",
    "            \n",
    "            pattern_key = (current[1], current[2])\n",
    "            if pattern_key not in pattern_dict:\n",
    "                pattern_dict[pattern_key] = {'total': 0, 'success': 0}\n",
    "            pattern_dict[pattern_key]['total'] += 1\n",
    "            if transition['success']:\n",
    "                pattern_dict[pattern_key]['success'] += 1\n",
    "            \n",
    "            if not transition['success']:\n",
    "                error = {\n",
    "                    'actual': (actual[1], actual[2]),\n",
    "                    'predicted': (predicted[1], predicted[2]),\n",
    "                    'confidence': pred['top_predictions'][0][1]\n",
    "                }\n",
    "                patterns['common_errors'].append(error)\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "def make_initial_predictions(predictor: BayesianPredictor, binned_features: Dict, n_steps: int) -> Dict:\n",
    "    predictions = {}\n",
    "    \n",
    "    for series_id, features in binned_features.items():\n",
    "        series_predictions = []\n",
    "        \n",
    "        for i in range(len(features) - n_steps):\n",
    "            current_state = predictor.tm.get_state_id((\n",
    "                features[i]['eodb_bin'],\n",
    "                features[i]['duration_bin'],\n",
    "                features[i]['slope_bin'],\n",
    "                features[i]['curvature_bin']\n",
    "            ))\n",
    "            \n",
    "            actual_future_state = predictor.tm.get_state_id((\n",
    "                features[i + n_steps]['eodb_bin'],\n",
    "                features[i + n_steps]['duration_bin'],\n",
    "                features[i + n_steps]['slope_bin'],\n",
    "                features[i + n_steps]['curvature_bin']\n",
    "            ))\n",
    "            \n",
    "            predicted_probs = predictor.predict_next_n_states(current_state, n_steps)\n",
    "            top_predictions = predictor.get_top_k_states(predicted_probs)\n",
    "            \n",
    "            series_predictions.append({\n",
    "                'current_state': current_state,\n",
    "                'actual_future_state': actual_future_state,\n",
    "                'predicted_probabilities': predicted_probs,\n",
    "                'top_predictions': top_predictions\n",
    "            })\n",
    "            \n",
    "        predictions[series_id] = series_predictions\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def analyze_feature_importance(predictions, predictor):\n",
    "    feature_accuracy = {\n",
    "        'eodb': {'linear': [], 'transition': []},\n",
    "        'duration': {'linear': [], 'transition': []},\n",
    "        'slope': {'linear': [], 'transition': []},\n",
    "        'curvature': {'linear': [], 'transition': []}\n",
    "    }\n",
    "    \n",
    "    for series_id, series_preds in predictions.items():\n",
    "        for pred in series_preds:\n",
    "            actual = pred['actual_future_state']\n",
    "            predicted = pred['top_predictions'][0][0]\n",
    "            \n",
    "            actual_features = predictor.tm.reverse_map[actual]\n",
    "            predicted_features = predictor.tm.reverse_map[predicted]\n",
    "            \n",
    "            region_type = 'transition' if actual_features[3] > 0 else 'linear'\n",
    "            \n",
    "            feature_accuracy['eodb'][region_type].append(actual_features[0] == predicted_features[0])\n",
    "            feature_accuracy['duration'][region_type].append(actual_features[1] == predicted_features[1])\n",
    "            feature_accuracy['slope'][region_type].append(actual_features[2] == predicted_features[2])\n",
    "            feature_accuracy['curvature'][region_type].append(actual_features[3] == predicted_features[3])\n",
    "    \n",
    "    return {k: {region: np.mean(vals) for region, vals in v.items()} \n",
    "            for k, v in feature_accuracy.items()}\n",
    "\n",
    "# Execution Block\n",
    "tm_data = pd.read_pickle(INPUT_CONFIG['transition_matrix_path'])\n",
    "binned_features = pd.read_pickle(INPUT_CONFIG['features_path'])\n",
    "predictor = BayesianPredictor(tm_data['transition_matrix'])\n",
    "predictions = make_predictions(predictor, binned_features, INPUT_CONFIG['n_steps_ahead'])\n",
    "\n",
    "# Analysis and Reporting\n",
    "print(\"\\nDiagnostic Information:\")\n",
    "series_id = list(predictions.keys())[0]\n",
    "series_predictions = predictions[series_id]\n",
    "y_points = [feature['raw_features']['eodb_level'] for feature in binned_features[series_id]]\n",
    "print(\"Sample Original EODB values:\", y_points[:5])\n",
    "\n",
    "sample_pred = series_predictions[0]\n",
    "print(\"\\nSample Prediction:\")\n",
    "print(\"Current State EODB:\", predictor.tm.reverse_map[sample_pred['current_state']][0])\n",
    "print(\"Actual Future EODB:\", predictor.tm.reverse_map[sample_pred['actual_future_state']][0])\n",
    "print(\"Top Predicted States EODB values:\", [predictor.tm.reverse_map[state_id][0] for state_id, prob in sample_pred['top_predictions']])\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importance = analyze_feature_importance(predictions, predictor)\n",
    "print(\"\\nFeature Importance Analysis by Region Type:\")\n",
    "for feature, region_accuracy in feature_importance.items():\n",
    "    print(f\"\\n{feature.capitalize()}:\")\n",
    "    for region, accuracy in region_accuracy.items():\n",
    "        print(f\"  {region.capitalize()} region accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Pattern Analysis\n",
    "pattern_analysis = analyze_duration_slope_patterns(predictions, predictor)\n",
    "print(\"\\nDuration-Slope Pattern Analysis:\")\n",
    "print(\"\\nLinear Region Patterns:\")\n",
    "for pattern, stats in sorted(pattern_analysis['linear_patterns'].items(), \n",
    "                           key=lambda x: x[1]['success']/x[1]['total'] if x[1]['total'] > 0 else 0, \n",
    "                           reverse=True)[:5]:\n",
    "    success_rate = stats['success']/stats['total'] if stats['total'] > 0 else 0\n",
    "    print(f\"Duration: {pattern[0]}, Slope: {pattern[1]}\")\n",
    "    print(f\"Success Rate: {success_rate:.2%} ({stats['success']}/{stats['total']} predictions)\")\n",
    "\n",
    "print(\"\\nTransition Region Patterns:\")\n",
    "for pattern, stats in sorted(pattern_analysis['transition_patterns'].items(), \n",
    "                           key=lambda x: x[1]['success']/x[1]['total'] if x[1]['total'] > 0 else 0, \n",
    "                           reverse=True)[:5]:\n",
    "    success_rate = stats['success']/stats['total'] if stats['total'] > 0 else 0\n",
    "    print(f\"Duration: {pattern[0]}, Slope: {pattern[1]}\")\n",
    "    print(f\"Success Rate: {success_rate:.2%} ({stats['success']}/{stats['total']} predictions)\")\n",
    "\n",
    "# Save predictions\n",
    "INPUT_CONFIG['output_path'].mkdir(exist_ok=True, parents=True)\n",
    "output_file = INPUT_CONFIG['output_path'] / INPUT_CONFIG['output_filename']\n",
    "pd.to_pickle(predictions, output_file)\n",
    "\n",
    "print(\"\\nPredictions completed and saved!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
